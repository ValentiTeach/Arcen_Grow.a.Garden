{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2e00a27-64ef-4431-967e-940768fda8fa",
      "metadata": {
        "id": "f2e00a27-64ef-4431-967e-940768fda8fa"
      },
      "source": [
        "# Getting started with Mistral AI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
      "metadata": {
        "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
        "outputId": "2edf235b-3924-47bf-85b0-e75db70d628b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.3-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.3-py3-none-any.whl (426 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.3/426.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 mistralai-1.9.3\n"
          ]
        }
      ],
      "source": [
        "! pip install mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b630861-a95e-4925-8525-d9461d3627ea",
      "metadata": {
        "id": "5b630861-a95e-4925-8525-d9461d3627ea"
      },
      "source": [
        "Our API is currently available through [La Plateforme](https://console.mistral.ai/). You need to activate payments on your account to enable your API keys. After a few moments, you will be able to use our `chat` endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2868793c-9065-459a-9a8e-214c31b98f1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "2868793c-9065-459a-9a8e-214c31b98f1d",
        "outputId": "262dc6c2-1670-4491-dd48-41a3537e4f9b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SDKError",
          "evalue": "API error occurred: Status 401\n{\"detail\":\"Unauthorized\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-205609575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMistral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m chat_response = client.chat.complete(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"What is the best French cheese?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mistralai/chat.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, parallel_tool_calls, prompt_mode, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4XX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mhttp_res_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             raise models.SDKError(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;34m\"API error occurred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_res_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             )\n",
            "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 401\n{\"detail\":\"Unauthorized\"}"
          ]
        }
      ],
      "source": [
        "from mistralai import Mistral\n",
        "api_key = \"TYPE YOUR API KEY\"\n",
        "model = \"mistral-large-latest\"\n",
        "\n",
        "client = Mistral(api_key=api_key)\n",
        "\n",
        "chat_response = client.chat.complete(\n",
        "    model=model,\n",
        "    messages=[{\"role\":\"user\", \"content\":\"What is the best French cheese?\"}]\n",
        ")\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b202fe-293b-4251-87c4-2bd7301ddede",
      "metadata": {
        "id": "01b202fe-293b-4251-87c4-2bd7301ddede"
      },
      "source": [
        "Or our embeddings endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e183befa-5db6-4758-9382-b7bfb3a55ff5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "e183befa-5db6-4758-9382-b7bfb3a55ff5",
        "outputId": "ba80aed9-f1dd-48d1-9087-35e282011131"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1340422503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistral-embed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m embeddings_response = client.embeddings.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Embed this sentence.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"As well as this one.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "model = \"mistral-embed\"\n",
        "\n",
        "embeddings_response = client.embeddings.create(\n",
        "    model=model,\n",
        "    inputs=[\"Embed this sentence.\", \"As well as this one.\"]\n",
        ")\n",
        "\n",
        "print(embeddings_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nBnI4U-ClTYM",
      "metadata": {
        "id": "nBnI4U-ClTYM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}